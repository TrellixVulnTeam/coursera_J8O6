With 20 convolution layers, you make zero progress without batch
normalization. With BN you get to >90% accuracy within 400
iterations.

Obviously this is a stupid example, but it shows you can have very
deep networks with batch normalization.
